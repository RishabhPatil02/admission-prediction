{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36404c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot, download_plotlyjs\n",
    "init_notebook_mode(connected = True)\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid', color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eee89d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   sop\n",
       "0   My goal is to combine my background in physics...\n",
       "1   The doctoral program will provide me with an o...\n",
       "2   Growing up, I always loved math and sciences. ...\n",
       "3   A desire to extend my knowledge and an enthusi...\n",
       "4   As a child born and raised in Delhi, India, I ...\n",
       "5   I am applying to Harvards doctoral program in ...\n",
       "6   When I came to college I wanted to be a doctor...\n",
       "7   I want to pursue a Ph.D. in Computer Science, ...\n",
       "8   Having worked as a teacher at Liaocheng Teache...\n",
       "9   In order to best contribute to the leading que...\n",
       "10  Certainly, my academic journey has not been wi...\n",
       "11  During my early studies I had no clue about ar...\n",
       "12  I am interested in the STRATFOR summer interns...\n",
       "13  Currently, I am working with USC Professor Bar...\n",
       "14  I did my undergraduate research on how familia...\n",
       "15  In the current time, new breakthroughs in tech...\n",
       "16  It is amazing to me what can be done through t...\n",
       "17  I can still clearly remember the day just like...\n",
       "18  Statement of Purpose for MS in Computer Scienc...\n",
       "19  I can still clearly remember the day just like...\n",
       "20  It was the International Conference on Machine...\n",
       "21  As the world's usage of technology has increas...\n",
       "22  Moving toward graduate school, I am interested...\n",
       "23  Few areas of my education have stimulated me t...>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sop.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0b0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[]\n",
    "# for i in range(14):\n",
    "#     l.append(df.iloc[i]['sop'].replace(\"ï¿½\",\"\"))\n",
    "# dfw = pd.DataFrame(l,columns =['sop'])\n",
    "# dfw.to_csv('../data/sop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c858ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def lemmatize_string(s):\n",
    "    nltk.download('wordnet')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    list2 = nltk.word_tokenize(s)\n",
    "    lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "    return lemmatized_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3eda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d05aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "for i in range(24):\n",
    "    l.append(lemmatize_string(df.iloc[i]['sop'].lower()))\n",
    "X = vectorizer.fit_transform(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06780a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=5, n_init=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2b1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6482e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " academic\n",
      " wa\n",
      " university\n",
      " architecture\n",
      " linguistics\n",
      " college\n",
      " believe\n",
      " landscape\n",
      " student\n",
      " opportunity\n",
      " experience\n",
      " work\n",
      " education\n",
      " field\n",
      " skill\n",
      " master\n",
      " research\n",
      " grade\n",
      " higher\n",
      " chinese\n",
      " stratfor\n",
      " study\n",
      " test\n",
      " networking\n",
      " activity\n",
      " urban\n",
      " program\n",
      " department\n",
      " english\n",
      " company\n",
      " professional\n",
      " east\n",
      " lack\n",
      " number\n",
      " landscaping\n",
      " design\n",
      " pursuit\n",
      " bluetooth\n",
      " year\n",
      " network\n",
      " school\n",
      " internship\n",
      " confidence\n",
      " help\n",
      " intelligence\n",
      " given\n",
      " affair\n",
      " deal\n",
      " ha\n",
      " editor\n",
      "\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " research\n",
      " model\n",
      " mechanism\n",
      " physic\n",
      " theory\n",
      " dr\n",
      " brain\n",
      " game\n",
      " mathematical\n",
      " simulation\n",
      " economics\n",
      " cell\n",
      " project\n",
      " neuron\n",
      " understand\n",
      " physical\n",
      " neuroscience\n",
      " mathematics\n",
      " response\n",
      " neural\n",
      " wa\n",
      " optimal\n",
      " usc\n",
      " rieke\n",
      " process\n",
      " pi\n",
      " information\n",
      " capacity\n",
      " computation\n",
      " role\n",
      " zero\n",
      " player\n",
      " empirical\n",
      " input\n",
      " memory\n",
      " gene\n",
      " proposal\n",
      " work\n",
      " group\n",
      " biological\n",
      " result\n",
      " shea\n",
      " morphology\n",
      " fairhall\n",
      " brown\n",
      " especially\n",
      " biophysical\n",
      " technique\n",
      " dynamic\n",
      " insight\n",
      "\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      " computer\n",
      " science\n",
      " programming\n",
      " technology\n",
      " wa\n",
      " field\n",
      " program\n",
      " software\n",
      " skill\n",
      " really\n",
      " application\n",
      " engineering\n",
      " project\n",
      " able\n",
      " knowledge\n",
      " need\n",
      " course\n",
      " interested\n",
      " felt\n",
      " just\n",
      " year\n",
      " research\n",
      " school\n",
      " electronic\n",
      " gadget\n",
      " microprocessor\n",
      " string\n",
      " programmer\n",
      " work\n",
      " new\n",
      " team\n",
      " development\n",
      " continue\n",
      " type\n",
      " developer\n",
      " problem\n",
      " ha\n",
      " understanding\n",
      " analysis\n",
      " tool\n",
      " potential\n",
      " career\n",
      " niversit\n",
      " prof\n",
      " strong\n",
      " day\n",
      " experience\n",
      " structure\n",
      " training\n",
      " subject\n",
      "\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      " chemistry\n",
      " xxx\n",
      " research\n",
      " gc\n",
      " did\n",
      " glass\n",
      " ms\n",
      " instrument\n",
      " uni\n",
      " chromium\n",
      " student\n",
      " lab\n",
      " ion\n",
      " spme\n",
      " looking\n",
      " clinical\n",
      " risk\n",
      " want\n",
      " new\n",
      " sample\n",
      " program\n",
      " adolescent\n",
      " instrumentation\n",
      " analytes\n",
      " changing\n",
      " water\n",
      " operation\n",
      " standard\n",
      " wa\n",
      " child\n",
      " conference\n",
      " working\n",
      " affect\n",
      " college\n",
      " professor\n",
      " teach\n",
      " molecular\n",
      " university\n",
      " doing\n",
      " gin\n",
      " aunt\n",
      " chemical\n",
      " substance\n",
      " love\n",
      " enjoy\n",
      " use\n",
      " nature\n",
      " like\n",
      " high\n",
      " undergraduate\n",
      "\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      " rockefeller\n",
      " research\n",
      " flow\n",
      " graduate\n",
      " ph\n",
      " neuroscience\n",
      " university\n",
      " professor\n",
      " sensory\n",
      " prepared\n",
      " alonso\n",
      " icme\n",
      " lele\n",
      " fluid\n",
      " aerodynamics\n",
      " model\n",
      " perception\n",
      " innovative\n",
      " interdisciplinary\n",
      " multidisciplinary\n",
      " stanford\n",
      " transition\n",
      " mechanic\n",
      " accurate\n",
      " program\n",
      " investigator\n",
      " leading\n",
      " science\n",
      " strong\n",
      " come\n",
      " unique\n",
      " continuing\n",
      " offer\n",
      " interested\n",
      " better\n",
      " academic\n",
      " question\n",
      " experience\n",
      " building\n",
      " faculty\n",
      " vosshall\n",
      " drawn\n",
      " measuring\n",
      " frontier\n",
      " supporting\n",
      " scientifically\n",
      " assay\n",
      " magnasco\n",
      " array\n",
      " excellent\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :50]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80d4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "import pickle\n",
    "with open('sop_model_picle','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e23f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (1, 2575))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Prediction\")\n",
    "X = vectorizer.transform([lemmatize_string(l[1])])\n",
    "predicted = model.predict(X)\n",
    "print(predicted),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4379b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
