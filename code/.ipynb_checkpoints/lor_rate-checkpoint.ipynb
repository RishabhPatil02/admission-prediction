{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9824665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot, download_plotlyjs\n",
    "init_notebook_mode(connected = True)\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2908bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   sop\n",
       "0   My goal is to combine my background in physics...\n",
       "1   The doctoral program will provide me with an o...\n",
       "2   Growing up, I always loved math and sciences. ...\n",
       "3   A desire to extend my knowledge and an enthusi...\n",
       "4   As a child born and raised in Delhi, India, I ...\n",
       "5   I am applying to Harvards doctoral program in ...\n",
       "6   When I came to college I wanted to be a doctor...\n",
       "7   I want to pursue a Ph.D. in Computer Science, ...\n",
       "8   Having worked as a teacher at Liaocheng Teache...\n",
       "9   In order to best contribute to the leading que...\n",
       "10  Certainly, my academic journey has not been wi...\n",
       "11  During my early studies I had no clue about ar...\n",
       "12  I am interested in the STRATFOR summer interns...\n",
       "13  Currently, I am working with USC Professor Bar...\n",
       "14  I did my undergraduate research on how familia...\n",
       "15  In the current time, new breakthroughs in tech...\n",
       "16  It is amazing to me what can be done through t...\n",
       "17  I can still clearly remember the day just like...\n",
       "18  Statement of Purpose for MS in Computer Scienc...\n",
       "19  I can still clearly remember the day just like...\n",
       "20  It was the International Conference on Machine...\n",
       "21  As the world's usage of technology has increas...\n",
       "22  Moving toward graduate school, I am interested...\n",
       "23  Few areas of my education have stimulated me t...>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sop.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6588c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def lemmatize_string(s):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    list2 = nltk.word_tokenize(s)\n",
    "    lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "    return lemmatized_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7c708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "for i in range(24):\n",
    "    l.append(lemmatize_string(df.iloc[i]['sop'].lower()))\n",
    "X = vectorizer.fit_transform(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af119b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 5\n",
    "with open('lor_model_picle','rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b793214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 681, 1140,   41, ...,  680,  679,    0],\n",
       "       [1031,  647,  673, ...,  745,  744,    0],\n",
       "       [1031,  717, 1035, ...,  736,  735,    0],\n",
       "       [ 505,  648,  147, ...,  693,  692,    0],\n",
       "       [ 697, 1031, 1140, ...,  607,  603,  585]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2715db47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " discipline\n",
      " highly\n",
      " ______\n",
      " asset\n",
      " 5th\n",
      " entered\n",
      " fox\n",
      " fundamental\n",
      " google\n",
      " hypothesis\n",
      " high\n",
      " going\n",
      " covered\n",
      " child\n",
      " eager\n",
      " flight\n",
      " activation\n",
      " foundation\n",
      " dyncomp\n",
      " actually\n",
      " behalf\n",
      " heterogeneous\n",
      " additionally\n",
      " fred\n",
      " govern\n",
      " aeroelasticity\n",
      " examine\n",
      " benefit\n",
      " biology\n",
      " evaluated\n",
      " audience\n",
      " advanced\n",
      " convinced\n",
      " hope\n",
      " custody\n",
      " computation\n",
      " exactly\n",
      " electricity\n",
      " behavioral\n",
      " aug2003\n",
      " chemistry\n",
      " ar\n",
      " hunger\n",
      " continues\n",
      " difficult\n",
      " ga\n",
      " chris\n",
      " curriculum\n",
      " challenged\n",
      " consider\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " gained\n",
      " destination\n",
      " dig\n",
      " gamma\n",
      " careful\n",
      " discount\n",
      " enable\n",
      " applicability\n",
      " health\n",
      " human\n",
      " codehost\n",
      " 1997\n",
      " difficult\n",
      " glass\n",
      " confidence\n",
      " hci\n",
      " fun\n",
      " certificate\n",
      " ications\n",
      " doshi\n",
      " abstract\n",
      " drs\n",
      " definition\n",
      " adapting\n",
      " connection\n",
      " confirmed\n",
      " exhibit\n",
      " festival\n",
      " arch\n",
      " hades\n",
      " eletrospray\n",
      " 666\n",
      " expression\n",
      " acquainted\n",
      " consequently\n",
      " eagerness\n",
      " delusional\n",
      " cellular\n",
      " broadened\n",
      " 2017\n",
      " excelled\n",
      " bridge\n",
      " collection\n",
      " excitement\n",
      " critically\n",
      " ample\n",
      " attained\n",
      " crucial\n",
      " bergers\n",
      " appreciation\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      " gained\n",
      " doubt\n",
      " gamma\n",
      " clarity\n",
      " foundation\n",
      " attraction\n",
      " forth\n",
      " collar\n",
      " computation\n",
      " exploit\n",
      " 1997\n",
      " game\n",
      " definition\n",
      " compared\n",
      " abstract\n",
      " domain\n",
      " ga\n",
      " emulate\n",
      " fashion\n",
      " drive\n",
      " aiken\n",
      " dream\n",
      " highlighted\n",
      " _________\n",
      " careerin\n",
      " awareness\n",
      " femlab\n",
      " 1999\n",
      " analytical\n",
      " alaska\n",
      " confident\n",
      " coupling\n",
      " confidence\n",
      " followed\n",
      " challenging\n",
      " constantly\n",
      " collection\n",
      " health\n",
      " coursework\n",
      " face\n",
      " framing\n",
      " aspiration\n",
      " 3lessed\n",
      " assuming\n",
      " aide\n",
      " commensurates\n",
      " economist\n",
      " excites\n",
      " connected\n",
      " caught\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      " confidence\n",
      " detailed\n",
      " analytic\n",
      " complexity\n",
      " 2002\n",
      " gained\n",
      " advisor\n",
      " appropriate\n",
      " acquired\n",
      " badminton\n",
      " constraint\n",
      " essential\n",
      " helping\n",
      " complement\n",
      " defining\n",
      " game\n",
      " fairhall\n",
      " hope\n",
      " economic\n",
      " hypothesize\n",
      " constructing\n",
      " health\n",
      " bank\n",
      " compartmental\n",
      " astrong\n",
      " computation\n",
      " foundation\n",
      " exploitation\n",
      " growth\n",
      " delta\n",
      " equation\n",
      " advance\n",
      " facility\n",
      " assigned\n",
      " contributing\n",
      " contemplating\n",
      " di\n",
      " gathering\n",
      " gamma\n",
      " __________\n",
      " empirical\n",
      " effective\n",
      " certified\n",
      " collar\n",
      " collected\n",
      " collection\n",
      " environment\n",
      " brought\n",
      " advice\n",
      " attracted\n",
      "\n",
      "\n",
      "Cluster 4:\n",
      " distinctively\n",
      " gained\n",
      " highly\n",
      " global\n",
      " fid\n",
      " confidence\n",
      " adaptive\n",
      " directed\n",
      " assumption\n",
      " fullest\n",
      " fewer\n",
      " day\n",
      " cable\n",
      " hypothesize\n",
      " goals\n",
      " began\n",
      " 1997\n",
      " aspire\n",
      " agency\n",
      " examine\n",
      " disrupted\n",
      " directly\n",
      " continuing\n",
      " foundation\n",
      " habit\n",
      " el\n",
      " brainstorming\n",
      " exactly\n",
      " adult\n",
      " cabbage\n",
      " character\n",
      " difficult\n",
      " behavioral\n",
      " gel\n",
      " glass\n",
      " endemic\n",
      " existed\n",
      " box\n",
      " engineeringmonica\n",
      " enable\n",
      " demanding\n",
      " emergence\n",
      " city\n",
      " finding\n",
      " architecture\n",
      " gf\n",
      " health\n",
      " able\n",
      " abc\n",
      " gene\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :50]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbb013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster(s):    \n",
    "    X = vectorizer.transform([lemmatize_string(s)])\n",
    "    predicted = model.predict(X)\n",
    "    return predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d88cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(s,order_centroids,true_k):\n",
    "    X = vectorizer.transform([lemmatize_string(s)])\n",
    "    distance=np.zeros((X.shape[0], true_k))\n",
    "    for k in range(true_k):\n",
    "        row_norm = np.linalg.norm(X - order_centroids[k, :], axis=1)\n",
    "        distance[:, k] = np.square(row_norm)\n",
    "    return distance.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26586174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(s,order_centroids,true_k):\n",
    "    d=get_distance(s,order_centroids,true_k)\n",
    "    s0=26/d[0]\n",
    "    s1=24/d[1]\n",
    "    s2=29/d[2]\n",
    "    s3=30/d[3]\n",
    "    s4=19/d[4]\n",
    "    final_score=(s0+s1+s2+s3+s4)/5\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f420d8d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (1172,) and requested shape (1,2575)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7c129a978d18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder_centroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b70e42e16aeb>\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(s, order_centroids, true_k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder_centroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder_centroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0ms0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ms1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0ms2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-924252b9527f>\u001b[0m in \u001b[0;36mget_distance\u001b[1;34m(s, order_centroids, true_k)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mrow_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0morder_centroids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdistance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sub_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    178\u001b[0m            [1, 2, 3]])\n\u001b[0;32m    179\u001b[0m     \"\"\"\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    121\u001b[0m                          'negative')\n\u001b[0;32m    122\u001b[0m     \u001b[0mextras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     it = np.nditer(\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'refs_ok'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zerosize_ok'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         op_flags=['readonly'], itershape=shape, order='C')\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (1172,) and requested shape (1,2575)"
     ]
    }
   ],
   "source": [
    "ll=[]\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(21):\n",
    "    x=get_score(l[i],order_centroids,true_k)\n",
    "    ll.append(x)\n",
    "    \n",
    "scaled = scaler.fit_transform(np.array(ll).reshape(-1, 1))\n",
    "for i in range(21):\n",
    "    print(scaled[i][0]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b3421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
