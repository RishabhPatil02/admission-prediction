{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dea6059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot, download_plotlyjs\n",
    "init_notebook_mode(connected = True)\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b77d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   sop\n",
       "0   My goal is to combine my background in physics...\n",
       "1   The doctoral program will provide me with an o...\n",
       "2   Growing up, I always loved math and sciences. ...\n",
       "3   A desire to extend my knowledge and an enthusi...\n",
       "4   As a child born and raised in Delhi, India, I ...\n",
       "5   I am applying to Harvards doctoral program in ...\n",
       "6   When I came to college I wanted to be a doctor...\n",
       "7   I want to pursue a Ph.D. in Computer Science, ...\n",
       "8   Having worked as a teacher at Liaocheng Teache...\n",
       "9   In order to best contribute to the leading que...\n",
       "10  Certainly, my academic journey has not been wi...\n",
       "11  During my early studies I had no clue about ar...\n",
       "12  I am interested in the STRATFOR summer interns...\n",
       "13  Currently, I am working with USC Professor Bar...\n",
       "14  I did my undergraduate research on how familia...\n",
       "15  In the current time, new breakthroughs in tech...\n",
       "16  It is amazing to me what can be done through t...\n",
       "17  I can still clearly remember the day just like...\n",
       "18  Statement of Purpose for MS in Computer Scienc...\n",
       "19  I can still clearly remember the day just like...\n",
       "20  It was the International Conference on Machine...\n",
       "21  As the world's usage of technology has increas...\n",
       "22  Moving toward graduate school, I am interested...\n",
       "23  Few areas of my education have stimulated me t...>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sop.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094dc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "for i in range(24):\n",
    "    l.append(df.iloc[i]['sop'].lower())\n",
    "X = vectorizer.fit_transform(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd5248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 2\n",
    "with open('model_picle','rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c41311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1968, 1501, 2010, ..., 1499, 1503,    0],\n",
       "       [ 398, 1041, 1968, ..., 1662, 1661,    0],\n",
       "       [ 489, 2505, 1908, ..., 1613, 1614,    0],\n",
       "       [2243, 2224,  404, ..., 1656, 1655,    0],\n",
       "       [ 489, 2320, 1833, ..., 1451, 1453, 1287]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5592a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " suggested\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      " community\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :1]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a145aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def lemmatize_string(s):\n",
    "    nltk.download('wordnet')\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    list2 = nltk.word_tokenize(s)\n",
    "    lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list2])\n",
    "    return lemmatized_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2882b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\risha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2239 features, but KMeans is expecting 2575 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c924eebd16cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlemmatize_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         X = self._validate_data(X, accept_sparse='csr', reset=False,\n\u001b[0m\u001b[0;32m    859\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                                 order='C', accept_large_sparse=False)\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\risha\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2239 features, but KMeans is expecting 2575 features as input."
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "# X = vectorizer.transform([lemmatize_string(l[10])])\n",
    "predicted = model.predict(X[20])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(X,order_centroids,true_k):\n",
    "    distance=np.zeros((X.shape[0], true_k))\n",
    "    for k in range(true_k):\n",
    "        row_norm = np.linalg.norm(X - order_centroids[k, :], axis=1)\n",
    "        distance[:, k] = np.square(row_norm)\n",
    "    return distance.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distance(X,order_centroids,true_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81724155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=37.0/(distance.tolist()[0][0])\n",
    "# b=41.0/(distance.tolist()[0][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
